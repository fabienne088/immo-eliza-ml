{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "df = pd.read_csv(\"../data/cleaned_properties.csv\")\n",
    "\n",
    "# Display the head\n",
    "display(df.head())\n",
    "df.shape\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for values APARTMENT and APARTMENT_BLOCK\n",
    "df_house1 = df[df[\"property_type\"] == \"HOUSE\"]\n",
    "df_house2 = df_house1[df_house1['subproperty_type'] != 'APARTMENT_BLOCK']\n",
    "\n",
    "df_house = df[(df[\"property_type\"] == \"HOUSE\") & (df['subproperty_type'] != 'APARTMENT_BLOCK')]\n",
    "\n",
    "df_house.head()\n",
    "print(df_house.info())\n",
    "print(df_house.shape)\n",
    "\n",
    "df_house[\"subproperty_type\"].unique()\n",
    "print(df_house[\"locality\"].unique())\n",
    "df_house.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables X and y: define the target and the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name X and y (specific columns=subset(houses))\n",
    "\n",
    "X = df_house.drop(columns=['price', 'property_type', 'subproperty_type', 'zip_code', 'locality', 'construction_year', 'cadastral_income']).to_numpy()\n",
    "y = df_house.price.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print chape\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y-shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical data to a numerical form.\n",
    "\n",
    "Data to convert:  'region', 'province', 'equipped_kitchen', 'state_building', 'epc', 'heating_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_house[['region', 'province', 'equipped_kitchen', 'state_building', 'epc', 'heating_type']]\n",
    "\n",
    "# See unique values of multiple columns\n",
    "for column in columns:\n",
    "    multi_columns = df_house[column].unique()\n",
    "    print(f\"Unique values in column '{column}': {multi_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.preprocessing.OneHotEncoder(*, categories='auto', drop=None, sparse_output=True, dtype=<class 'numpy.float64'>, handle_unknown='error', min_frequency=None, max_categories=None, feature_name_combiner='concat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohe on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming df_house contains the DataFrame and columns contains the relevant columns\n",
    "columns_to_encode = ['region', 'province', 'equipped_kitchen', 'state_building', 'epc', 'heating_type']\n",
    "\n",
    "# Extracting the columns to be encoded\n",
    "data_to_encode = df_house[columns_to_encode]\n",
    "\n",
    "# Creating the OneHotEncoder object\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fitting and transforming the data\n",
    "encoded_data = encoder.fit_transform(data_to_encode)\n",
    "print(type(encoded_data))\n",
    "\n",
    "# Converting the encoded data to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(input_features=columns_to_encode))\n",
    "\n",
    "# Concatenating the encoded DataFrame with the original DataFrame\n",
    "df_house_encoded = pd.concat([df_house.drop(columns=columns_to_encode), encoded_df], axis=1)\n",
    "display(df_house_encoded.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_house_encoded))\n",
    "display(df_house_encoded.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing with mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with NaN to imputate with mean\n",
    "- surface_land_sqm                      36254\n",
    "- primary_energy_consumption_sqm        26564\n",
    "- nbr_frontages                         26344\n",
    "- terrace_sqm                           13140\n",
    "- total_area_sqm                        7615\n",
    "- garden_sqm                            2939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assuming X_train is your NumPy array and columns_to_impute contains the relevant column names\n",
    "columns_to_impute = ['surface_land_sqm', 'primary_energy_consumption_sqm', 'nbr_frontages', 'terrace_sqm', 'total_area_sqm', 'garden_sqm']\n",
    "columns = df_house.drop(columns=['price', 'property_type', 'subproperty_type', 'zip_code', 'locality', 'construction_year', 'cadastral_income']).columns \n",
    "\n",
    "# Convert X_train to a DataFrame with appropriate column names\n",
    "X_train_df = pd.DataFrame(X_train, columns=columns)\n",
    "\n",
    "# Find the indices of the columns to impute\n",
    "column_indices = [list(X_train_df.columns).index(col) for col in columns_to_impute]\n",
    "print(column_indices)\n",
    "\n",
    "# Create SimpleImputer object\n",
    "imp_mean = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit the imputer to the selected columns in X_train\n",
    "imp_mean.fit(X_train[:, column_indices])\n",
    "\n",
    "# Transform the selected columns in X_train with the fitted imputer\n",
    "X_train_imputed = X_train.copy()  # Create a copy of X_train\n",
    "X_train_imputed[:, column_indices] = imp_mean.transform(X_train[:, column_indices])\n",
    "\n",
    "# X_train_imputed now contains X_train with missing values imputed using the mean strategy for the selected columns\n",
    "\n",
    "X_train_imputed.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohe on np.array with imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming X_train_imputed is your numpy array and columns_to_encode is a list of column names to encode\n",
    "columns_to_encode = ['region', 'province', 'equipped_kitchen', 'state_building', 'epc', 'heating_type']\n",
    "columns = df_house.drop(columns=['price', 'property_type', 'subproperty_type', 'zip_code', 'locality', 'construction_year', 'cadastral_income']).columns\n",
    "df2 = df_house.drop(columns=['price', 'property_type', 'subproperty_type', 'zip_code', 'locality', 'construction_year', 'cadastral_income'])\n",
    "cols = df2.columns.to_list\n",
    "print(cols)\n",
    "\n",
    "# Convert X_train_imputed to a DataFrame with appropriate column names\n",
    "X_train_df = pd.DataFrame(X_train_imputed, columns=columns)\n",
    "print(X_train_df.shape)\n",
    "\n",
    "\n",
    "# Handling NaN values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')  # You can choose a strategy that fits your data\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(X_train_df), columns=X_train_df.columns)\n",
    "print(data_imputed.shape)\n",
    "\n",
    "# Creating the OneHotEncoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fitting and transforming the data\n",
    "encoded_data = encoder.fit_transform(data_imputed)\n",
    "\n",
    "# Converting the encoded data to a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray())\n",
    "\n",
    "# Selecting non-encode columns from the original X_train_imputed array\n",
    "non_encoded_columns = np.delete(X_train_imputed, np.where(np.isin(X_train_df.columns, columns_to_encode)), axis=1)\n",
    "print(non_encoded_columns.shape)\n",
    "print(type(non_encoded_columns))\n",
    "\n",
    "# Concatenating the non-encoded columns with the encoded array\n",
    "X_train_encoded = np.concatenate([non_encoded_columns, encoded_array], axis=1)\n",
    "\n",
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = df_house['total_area_sqm']\n",
    "y = df_house['primary_energy_consumption_sqm']\n",
    "z = df_house['price']\n",
    "\n",
    "ax.view_init(180, 180)\n",
    "ax.scatter(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "#plt.tight_layout()\n",
    "axes[0].scatter(df_house['total_area_sqm'], df_house['price'])\n",
    "axes[1].scatter(df_house['primary_energy_consumption_sqm'],df_house['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house.select_dtypes(exclude='object').corr().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two figures so it is better visualized\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "X = df_house.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "half = len(X.columns)//2\n",
    "\n",
    "\n",
    "fig1 = sns.pairplot(df, x_vars=X.columns[half:], y_vars='price')\n",
    "fig2 = sns.pairplot(df, x_vars=X.columns[:half], y_vars='price')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name X and y (specific columns=subset(houses))\n",
    "\n",
    "X = df_house[\"total_area_sqm\"].to_numpy().reshape(-1,1)\n",
    "y = df_house[\"price\"].to_numpy().reshape(-1,1)\n",
    "\n",
    "# Split the data into training and test data\n",
    "X_train1, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "print(type(X_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#r = np.corrcoef(X, y)[0,1]\n",
    "#display(r)\n",
    "#print(f\"Correlation Coefficient between 'YearsExperience' and 'Salary': {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize SimpleImputer with strategy 'mean'\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit the imputer to the data\n",
    "imputer.fit(X_train1)\n",
    "\n",
    "# Transform the data, replacing missing values\n",
    "X_train_imputed = imputer.transform(X_train1)\n",
    "\n",
    "print(X_train_imputed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import LinearRegression from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create regressor and instantiate LinearRegression class\n",
    "reg = LinearRegression()\n",
    "print(type(reg))\n",
    "\n",
    "# Train the model with X_train and  y_train\n",
    "reg.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display score of training model\n",
    "score = reg.score(X_train_imputed, y_train)\n",
    "print(score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model on the test dataset\n",
    "reg.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display score of test model\n",
    "score = reg.score(X_test, y_test)\n",
    "print(score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to flatten 2D lists so it can be used by plotly\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "# Set up and fit the linear regressor\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Flatten the prediction and expected lists\n",
    "predicted = flatten(lin_reg.predict(X_test))\n",
    "expected = flatten(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two functions:\n",
    "\n",
    "train : has as input X train y train output the model already trained\n",
    "\n",
    "evaluate: Takes (the trained model, X test and y test,) and outputs the score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

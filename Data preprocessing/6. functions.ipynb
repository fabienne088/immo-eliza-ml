{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>subproperty_type</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>locality</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>total_area_sqm</th>\n",
       "      <th>surface_land_sqm</th>\n",
       "      <th>...</th>\n",
       "      <th>fl_garden</th>\n",
       "      <th>garden_sqm</th>\n",
       "      <th>fl_swimming_pool</th>\n",
       "      <th>fl_floodzone</th>\n",
       "      <th>state_building</th>\n",
       "      <th>primary_energy_consumption_sqm</th>\n",
       "      <th>epc</th>\n",
       "      <th>heating_type</th>\n",
       "      <th>fl_double_glazing</th>\n",
       "      <th>cadastral_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>2050</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.0</td>\n",
       "      <td>C</td>\n",
       "      <td>GAS</td>\n",
       "      <td>1</td>\n",
       "      <td>922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>East Flanders</td>\n",
       "      <td>Gent</td>\n",
       "      <td>9185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.0</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>335000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>Brussels-Capital</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Turnhout</td>\n",
       "      <td>2275</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>982700.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>DUPLEX</td>\n",
       "      <td>Wallonia</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "      <td>Nivelles</td>\n",
       "      <td>1410</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price property_type subproperty_type            region         province  \\\n",
       "0  225000.0     APARTMENT        APARTMENT          Flanders          Antwerp   \n",
       "1  449000.0         HOUSE            HOUSE          Flanders    East Flanders   \n",
       "2  335000.0     APARTMENT        APARTMENT  Brussels-Capital         Brussels   \n",
       "3  501000.0         HOUSE            HOUSE          Flanders          Antwerp   \n",
       "4  982700.0     APARTMENT           DUPLEX          Wallonia  Walloon Brabant   \n",
       "\n",
       "   locality  zip_code  construction_year  total_area_sqm  surface_land_sqm  \\\n",
       "0   Antwerp      2050             1963.0           100.0               NaN   \n",
       "1      Gent      9185                NaN             NaN             680.0   \n",
       "2  Brussels      1070                NaN           142.0               NaN   \n",
       "3  Turnhout      2275             2024.0           187.0             505.0   \n",
       "4  Nivelles      1410             2022.0           169.0               NaN   \n",
       "\n",
       "   ...  fl_garden  garden_sqm fl_swimming_pool  fl_floodzone  state_building  \\\n",
       "0  ...          0         0.0                0             0             NaN   \n",
       "1  ...          0         0.0                0             0             NaN   \n",
       "2  ...          0         0.0                0             1          AS_NEW   \n",
       "3  ...          0         0.0                0             1             NaN   \n",
       "4  ...          1       142.0                0             0          AS_NEW   \n",
       "\n",
       "   primary_energy_consumption_sqm  epc  heating_type  fl_double_glazing  \\\n",
       "0                           231.0    C           GAS                  1   \n",
       "1                           221.0    C           NaN                  1   \n",
       "2                             NaN  NaN           GAS                  0   \n",
       "3                            99.0    A           NaN                  0   \n",
       "4                            19.0   A+           GAS                  0   \n",
       "\n",
       "   cadastral_income  \n",
       "0             922.0  \n",
       "1             406.0  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37211 entries, 1 to 75506\n",
      "Data columns (total 27 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   price                           37211 non-null  float64\n",
      " 1   property_type                   37211 non-null  object \n",
      " 2   subproperty_type                37211 non-null  object \n",
      " 3   region                          37211 non-null  object \n",
      " 4   province                        37211 non-null  object \n",
      " 5   locality                        37211 non-null  object \n",
      " 6   zip_code                        37211 non-null  int64  \n",
      " 7   construction_year               19969 non-null  float64\n",
      " 8   total_area_sqm                  32360 non-null  float64\n",
      " 9   surface_land_sqm                37211 non-null  float64\n",
      " 10  nbr_frontages                   29563 non-null  float64\n",
      " 11  nbr_bedrooms                    37211 non-null  float64\n",
      " 12  equipped_kitchen                20753 non-null  object \n",
      " 13  fl_furnished                    37211 non-null  int64  \n",
      " 14  fl_open_fire                    37211 non-null  int64  \n",
      " 15  fl_terrace                      37211 non-null  int64  \n",
      " 16  terrace_sqm                     28393 non-null  float64\n",
      " 17  fl_garden                       37211 non-null  int64  \n",
      " 18  garden_sqm                      34850 non-null  float64\n",
      " 19  fl_swimming_pool                37211 non-null  int64  \n",
      " 20  fl_floodzone                    37211 non-null  int64  \n",
      " 21  state_building                  25682 non-null  object \n",
      " 22  primary_energy_consumption_sqm  27141 non-null  float64\n",
      " 23  epc                             28490 non-null  object \n",
      " 24  heating_type                    23935 non-null  object \n",
      " 25  fl_double_glazing               37211 non-null  int64  \n",
      " 26  cadastral_income                20043 non-null  float64\n",
      "dtypes: float64(10), int64(8), object(9)\n",
      "memory usage: 7.9+ MB\n",
      "None\n",
      "(37211, 27)\n",
      "['Gent' 'Turnhout' 'Halle-Vilvoorde' 'Brugge' 'Sint-Niklaas' 'Charleroi'\n",
      " 'Veurne' 'LiÃ¨ge' 'Brussels' 'Dendermonde' 'Bastogne' 'Mons' 'Tournai'\n",
      " 'Nivelles' 'Aalst' 'Oudenaarde' 'Philippeville' 'Leuven' 'Dinant' 'Ieper'\n",
      " 'Kortrijk' 'Antwerp' 'Huy' 'Marche-en-Famenne' 'Mouscron' 'Verviers'\n",
      " 'Diksmuide' 'Soignies' 'Mechelen' 'Oostend' 'Namur' 'Hasselt' 'Tongeren'\n",
      " 'Arlon' 'NeufchÃ¢teau' 'Thuin' 'Waremme' 'Virton' 'Roeselare' 'Ath'\n",
      " 'Maaseik' 'Tielt' 'Eeklo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "construction_year                 17242\n",
       "cadastral_income                  17168\n",
       "equipped_kitchen                  16458\n",
       "heating_type                      13276\n",
       "state_building                    11529\n",
       "primary_energy_consumption_sqm    10070\n",
       "terrace_sqm                        8818\n",
       "epc                                8721\n",
       "nbr_frontages                      7648\n",
       "total_area_sqm                     4851\n",
       "garden_sqm                         2361\n",
       "fl_double_glazing                     0\n",
       "fl_floodzone                          0\n",
       "fl_swimming_pool                      0\n",
       "fl_garden                             0\n",
       "price                                 0\n",
       "fl_terrace                            0\n",
       "fl_open_fire                          0\n",
       "property_type                         0\n",
       "nbr_bedrooms                          0\n",
       "surface_land_sqm                      0\n",
       "zip_code                              0\n",
       "locality                              0\n",
       "province                              0\n",
       "region                                0\n",
       "subproperty_type                      0\n",
       "fl_furnished                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "df = pd.read_csv(\"../data/cleaned_properties.csv\")\n",
    "\n",
    "# Display the head\n",
    "display(df.head())\n",
    "df.shape\n",
    "df.columns\n",
    "\n",
    "# Filter the DataFrame for values APARTMENT and APARTMENT_BLOCK\n",
    "df_house1 = df[df[\"property_type\"] == \"HOUSE\"]\n",
    "df_house2 = df_house1[df_house1['subproperty_type'] != 'APARTMENT_BLOCK']\n",
    "\n",
    "df_house = df[(df[\"property_type\"] == \"HOUSE\") & (df['subproperty_type'] != 'APARTMENT_BLOCK')]\n",
    "\n",
    "df_house.head()\n",
    "print(df_house.info())\n",
    "print(df_house.shape)\n",
    "\n",
    "df_house[\"subproperty_type\"].unique()\n",
    "print(df_house[\"locality\"].unique())\n",
    "df_house.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables X and y: define the target and the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (37211, 20)\n",
      "y-shape:  (37211,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29768 entries, 8081 to 31954\n",
      "Data columns (total 20 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   region                          29768 non-null  object \n",
      " 1   province                        29768 non-null  object \n",
      " 2   total_area_sqm                  25900 non-null  float64\n",
      " 3   surface_land_sqm                29768 non-null  float64\n",
      " 4   nbr_frontages                   23670 non-null  float64\n",
      " 5   nbr_bedrooms                    29768 non-null  float64\n",
      " 6   equipped_kitchen                16580 non-null  object \n",
      " 7   fl_furnished                    29768 non-null  int64  \n",
      " 8   fl_open_fire                    29768 non-null  int64  \n",
      " 9   fl_terrace                      29768 non-null  int64  \n",
      " 10  terrace_sqm                     22712 non-null  float64\n",
      " 11  fl_garden                       29768 non-null  int64  \n",
      " 12  garden_sqm                      27915 non-null  float64\n",
      " 13  fl_swimming_pool                29768 non-null  int64  \n",
      " 14  fl_floodzone                    29768 non-null  int64  \n",
      " 15  state_building                  20592 non-null  object \n",
      " 16  primary_energy_consumption_sqm  21674 non-null  float64\n",
      " 17  epc                             22766 non-null  object \n",
      " 18  heating_type                    19124 non-null  object \n",
      " 19  fl_double_glazing               29768 non-null  int64  \n",
      "dtypes: float64(7), int64(7), object(6)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Name X and y (specific columns=subset(houses))\n",
    "X = df_house.drop(columns=['price', 'subproperty_type', 'property_type', 'zip_code', 'locality', 'construction_year', 'cadastral_income'])\n",
    "y = df_house['price']\n",
    "\n",
    "# Print shape\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y-shape: \", y.shape)\n",
    "\n",
    "# Split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imputing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values:\n",
    "- numerical: mean\n",
    "- categorical: most frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equipped_kitchen                  13188\n",
      "heating_type                      10644\n",
      "state_building                     9176\n",
      "primary_energy_consumption_sqm     8094\n",
      "terrace_sqm                        7056\n",
      "epc                                7002\n",
      "nbr_frontages                      6098\n",
      "total_area_sqm                     3868\n",
      "garden_sqm                         1853\n",
      "fl_floodzone                          0\n",
      "fl_swimming_pool                      0\n",
      "region                                0\n",
      "fl_garden                             0\n",
      "province                              0\n",
      "fl_terrace                            0\n",
      "fl_open_fire                          0\n",
      "fl_furnished                          0\n",
      "nbr_bedrooms                          0\n",
      "surface_land_sqm                      0\n",
      "fl_double_glazing                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "def impute_data(X_train):\n",
    "    \"\"\"\n",
    "    Imputes missing values in both numerical and categorical columns of the input DataFrame using SimpleImputer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input DataFrame containing columns with missing values.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Select columns with numerical and categorical data\n",
    "    numeric_cols = X_train.select_dtypes(exclude='object').columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Impute missing values for numerical columns\n",
    "    numeric_imputer = SimpleImputer(strategy='mean')  \n",
    "    X_train[numeric_cols] = numeric_imputer.fit_transform(X_train[numeric_cols])\n",
    "\n",
    "    # Impute missing values for categorical columns\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')  \n",
    "    X_train[categorical_cols] = categorical_imputer.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "    return X_train\n",
    "\n",
    "# Example usage:\n",
    "#X_train_imputed = impute_data(X_train)\n",
    "print(X_train.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in both X_train and x_test\n",
    "X_train_imputed = impute_data(X_train)\n",
    "X_test_imputed = impute_data(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rescaling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Encode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_data(X_train):\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in the input DataFrame using OneHotEncoder.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input DataFrame containing categorical columns to be encoded.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        DataFrame with categorical columns encoded using one-hot encoding.\n",
    "    \"\"\"\n",
    "    # Select the columns with categorical values\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Initialize the encoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_array = encoder.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "    # Convert the encoded array into a DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([X_train, encoded_df], axis=1)\n",
    "\n",
    "    # Drop the original categorical columns if needed\n",
    "    result_df.drop(columns=categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "    print(result_df.isna().sum().sort_values(ascending=False)) \n",
    "\n",
    "# Example usage:\n",
    "# X_train_encoded = encode_data(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult_df\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "result_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pipeline: Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Preprocesses training and test data including imputation, encoding, and scaling.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input training DataFrame.\n",
    "    X_test : pandas DataFrame\n",
    "        Input test DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple of pandas DataFrames\n",
    "        Preprocessed training and test DataFrames.\n",
    "    \"\"\"\n",
    "    # Separate numerical and categorical columns\n",
    "    numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Define preprocessing steps for numerical and categorical data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "    # Fit and transform the preprocessing steps on training data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Convert the processed data into DataFrames\n",
    "    X_train_processed = pd.DataFrame(X_train_processed, columns=numeric_cols.tolist() +\n",
    "                                     preprocessor.named_transformers_['cat']\n",
    "                                     .named_steps['onehot'].get_feature_names_out(categorical_cols).tolist())\n",
    "    X_test_processed = pd.DataFrame(X_test_processed, columns=numeric_cols.tolist() +\n",
    "                                    preprocessor.named_transformers_['cat']\n",
    "                                    .named_steps['onehot'].get_feature_names_out(categorical_cols).tolist())\n",
    "\n",
    "    return X_train_processed, X_test_processed\n",
    "\n",
    "# Preprocess training and test data\n",
    "X_train_processed, X_test_processed = preprocess_data(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rescaling numeric features (hint: standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- epc_A\n- epc_A+\n- epc_A++\n- epc_B\n- epc_C\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_train_processed\u001b[38;5;241m.\u001b[39mdrop(numeric_features\u001b[38;5;241m.\u001b[39mcolumns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), scaled_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Use final_df for your linear regression model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Transform the numeric features in the test set using the parameters learned from the training set\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat64\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint64\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Combine the scaled numeric features with the encoded categorical features\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# You may need to concatenate these with the encoded categorical features from step 2\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Depending on how you've encoded the categorical features\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Now, X_train_scaled and X_test_scaled contain the rescaled numeric features\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# You can use these in your linear regression model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fabie\\OneDrive\\Documenten\\BeCodeGhent\\Projects\\immo-eliza-ml\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\fabie\\OneDrive\\Documenten\\BeCodeGhent\\Projects\\immo-eliza-ml\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\fabie\\OneDrive\\Documenten\\BeCodeGhent\\Projects\\immo-eliza-ml\\.venv\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\fabie\\OneDrive\\Documenten\\BeCodeGhent\\Projects\\immo-eliza-ml\\.venv\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- epc_A\n- epc_A+\n- epc_A++\n- epc_B\n- epc_C\n- ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# X_train_processed contains numeric features\n",
    "numeric_features = X_train_processed.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Fit and transform the numeric features in the training set\n",
    "scaled_features = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Convert the scaled features array back to a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=numeric_features.columns)\n",
    "\n",
    "# Concatenate scaled numeric features with other columns in the original DataFrame\n",
    "# Assuming X_train_processed contains both categorical and numeric features\n",
    "final_df = pd.concat([X_train_processed.drop(numeric_features.columns, axis=1), scaled_df], axis=1)\n",
    "\n",
    "# Use final_df for your linear regression model\n",
    "\n",
    "# Transform the numeric features in the test set using the parameters learned from the training set\n",
    "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "\n",
    "# Combine the scaled numeric features with the encoded categorical features\n",
    "# You may need to concatenate these with the encoded categorical features from step 2\n",
    "# Depending on how you've encoded the categorical features\n",
    "\n",
    "# Now, X_train_scaled and X_test_scaled contain the rescaled numeric features\n",
    "# You can use these in your linear regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in the input DataFrames using OneHotEncoder.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input training DataFrame.\n",
    "    X_test : pandas DataFrame\n",
    "        Input test DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple of pandas DataFrames\n",
    "        Encoded training and test DataFrames.\n",
    "    \"\"\"\n",
    "    # Select the columns with categorical values\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Initialize the encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Fit and transform on training data\n",
    "    X_train_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "    # Convert the encoded data into DataFrames\n",
    "    X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "    X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "    # Drop original categorical columns from both training and test data\n",
    "    X_train.drop(columns=categorical_cols, inplace=True)\n",
    "    X_test.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "    # Concatenate encoded data with remaining data\n",
    "    X_train_final = pd.concat([X_train.reset_index(drop=True), X_train_encoded_df.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = pd.concat([X_test.reset_index(drop=True), X_test_encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return X_train_final, X_test_final\n",
    "\n",
    "# Apply one-hot encoding to training and test data\n",
    "X_train_encoded, X_test_encoded = one_hot_encode(X_train.copy(), X_test.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression: imputing NaN, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.56506221423302 %\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([518912., 203520., 643072., ..., 781312., 360960., 343552.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.21152166944702 %\n",
      "Training R^2 score: 32.56506221423302 %\n",
      "Testing R^2 score: 41.21152166944702 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the processed X_train and y_train\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Display score of training model\n",
    "training_score = model.score(X_train_processed, y_train)\n",
    "print(training_score*100, \"%\")\n",
    "\n",
    "\n",
    "# Once the model is trained, you can use it to make predictions on new data, \n",
    "# for example, the processed X_test\n",
    "predictions = model.predict(X_test_processed)\n",
    "print(type(predictions))\n",
    "display(predictions)\n",
    "\n",
    "# Display score of test model\n",
    "testing_score = model.score(X_test_processed, y_test)\n",
    "print(testing_score*100, \"%\")\n",
    "\n",
    "print(\"Training R^2 score:\", training_score*100, \"%\")\n",
    "print(\"Testing R^2 score:\", testing_score*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression: imputing NaN, OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model using the processed X_train and y_train\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mfinal_df\u001b[49m, y_train)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Display score of training model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m training_score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(final_df, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the processed X_train and y_train\n",
    "model.fit(final_df, y_train)\n",
    "\n",
    "# Display score of training model\n",
    "training_score = model.score(final_df, y_train)\n",
    "print(training_score*100, \"%\")\n",
    "\n",
    "\n",
    "# Once the model is trained, you can use it to make predictions on new data, \n",
    "# for example, the processed X_test\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(type(predictions))\n",
    "display(predictions)\n",
    "\n",
    "# Display score of test model\n",
    "testing_score = model.score(X_test_scaled, y_test)\n",
    "print(testing_score*100, \"%\")\n",
    "\n",
    "print(\"Training R^2 score:\", training_score*100, \"%\")\n",
    "print(\"Testing R^2 score:\", testing_score*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

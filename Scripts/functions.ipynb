{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>subproperty_type</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>locality</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>total_area_sqm</th>\n",
       "      <th>surface_land_sqm</th>\n",
       "      <th>...</th>\n",
       "      <th>fl_garden</th>\n",
       "      <th>garden_sqm</th>\n",
       "      <th>fl_swimming_pool</th>\n",
       "      <th>fl_floodzone</th>\n",
       "      <th>state_building</th>\n",
       "      <th>primary_energy_consumption_sqm</th>\n",
       "      <th>epc</th>\n",
       "      <th>heating_type</th>\n",
       "      <th>fl_double_glazing</th>\n",
       "      <th>cadastral_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>2050</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.0</td>\n",
       "      <td>C</td>\n",
       "      <td>GAS</td>\n",
       "      <td>1</td>\n",
       "      <td>922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>East Flanders</td>\n",
       "      <td>Gent</td>\n",
       "      <td>9185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.0</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>335000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>Brussels-Capital</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Turnhout</td>\n",
       "      <td>2275</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>982700.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>DUPLEX</td>\n",
       "      <td>Wallonia</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "      <td>Nivelles</td>\n",
       "      <td>1410</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price property_type subproperty_type            region         province  \\\n",
       "0  225000.0     APARTMENT        APARTMENT          Flanders          Antwerp   \n",
       "1  449000.0         HOUSE            HOUSE          Flanders    East Flanders   \n",
       "2  335000.0     APARTMENT        APARTMENT  Brussels-Capital         Brussels   \n",
       "3  501000.0         HOUSE            HOUSE          Flanders          Antwerp   \n",
       "4  982700.0     APARTMENT           DUPLEX          Wallonia  Walloon Brabant   \n",
       "\n",
       "   locality  zip_code  construction_year  total_area_sqm  surface_land_sqm  \\\n",
       "0   Antwerp      2050             1963.0           100.0               NaN   \n",
       "1      Gent      9185                NaN             NaN             680.0   \n",
       "2  Brussels      1070                NaN           142.0               NaN   \n",
       "3  Turnhout      2275             2024.0           187.0             505.0   \n",
       "4  Nivelles      1410             2022.0           169.0               NaN   \n",
       "\n",
       "   ...  fl_garden  garden_sqm fl_swimming_pool  fl_floodzone  state_building  \\\n",
       "0  ...          0         0.0                0             0             NaN   \n",
       "1  ...          0         0.0                0             0             NaN   \n",
       "2  ...          0         0.0                0             1          AS_NEW   \n",
       "3  ...          0         0.0                0             1             NaN   \n",
       "4  ...          1       142.0                0             0          AS_NEW   \n",
       "\n",
       "   primary_energy_consumption_sqm  epc  heating_type  fl_double_glazing  \\\n",
       "0                           231.0    C           GAS                  1   \n",
       "1                           221.0    C           NaN                  1   \n",
       "2                             NaN  NaN           GAS                  0   \n",
       "3                            99.0    A           NaN                  0   \n",
       "4                            19.0   A+           GAS                  0   \n",
       "\n",
       "   cadastral_income  \n",
       "0             922.0  \n",
       "1             406.0  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37211 entries, 1 to 75506\n",
      "Data columns (total 27 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   price                           37211 non-null  float64\n",
      " 1   property_type                   37211 non-null  object \n",
      " 2   subproperty_type                37211 non-null  object \n",
      " 3   region                          37211 non-null  object \n",
      " 4   province                        37211 non-null  object \n",
      " 5   locality                        37211 non-null  object \n",
      " 6   zip_code                        37211 non-null  int64  \n",
      " 7   construction_year               19969 non-null  float64\n",
      " 8   total_area_sqm                  32360 non-null  float64\n",
      " 9   surface_land_sqm                37211 non-null  float64\n",
      " 10  nbr_frontages                   29563 non-null  float64\n",
      " 11  nbr_bedrooms                    37211 non-null  float64\n",
      " 12  equipped_kitchen                20753 non-null  object \n",
      " 13  fl_furnished                    37211 non-null  int64  \n",
      " 14  fl_open_fire                    37211 non-null  int64  \n",
      " 15  fl_terrace                      37211 non-null  int64  \n",
      " 16  terrace_sqm                     28393 non-null  float64\n",
      " 17  fl_garden                       37211 non-null  int64  \n",
      " 18  garden_sqm                      34850 non-null  float64\n",
      " 19  fl_swimming_pool                37211 non-null  int64  \n",
      " 20  fl_floodzone                    37211 non-null  int64  \n",
      " 21  state_building                  25682 non-null  object \n",
      " 22  primary_energy_consumption_sqm  27141 non-null  float64\n",
      " 23  epc                             28490 non-null  object \n",
      " 24  heating_type                    23935 non-null  object \n",
      " 25  fl_double_glazing               37211 non-null  int64  \n",
      " 26  cadastral_income                20043 non-null  float64\n",
      "dtypes: float64(10), int64(8), object(9)\n",
      "memory usage: 7.9+ MB\n",
      "None\n",
      "(37211, 27)\n",
      "['Gent' 'Turnhout' 'Halle-Vilvoorde' 'Brugge' 'Sint-Niklaas' 'Charleroi'\n",
      " 'Veurne' 'LiÃ¨ge' 'Brussels' 'Dendermonde' 'Bastogne' 'Mons' 'Tournai'\n",
      " 'Nivelles' 'Aalst' 'Oudenaarde' 'Philippeville' 'Leuven' 'Dinant' 'Ieper'\n",
      " 'Kortrijk' 'Antwerp' 'Huy' 'Marche-en-Famenne' 'Mouscron' 'Verviers'\n",
      " 'Diksmuide' 'Soignies' 'Mechelen' 'Oostend' 'Namur' 'Hasselt' 'Tongeren'\n",
      " 'Arlon' 'NeufchÃ¢teau' 'Thuin' 'Waremme' 'Virton' 'Roeselare' 'Ath'\n",
      " 'Maaseik' 'Tielt' 'Eeklo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "construction_year                 17242\n",
       "cadastral_income                  17168\n",
       "equipped_kitchen                  16458\n",
       "heating_type                      13276\n",
       "state_building                    11529\n",
       "primary_energy_consumption_sqm    10070\n",
       "terrace_sqm                        8818\n",
       "epc                                8721\n",
       "nbr_frontages                      7648\n",
       "total_area_sqm                     4851\n",
       "garden_sqm                         2361\n",
       "fl_double_glazing                     0\n",
       "fl_floodzone                          0\n",
       "fl_swimming_pool                      0\n",
       "fl_garden                             0\n",
       "price                                 0\n",
       "fl_terrace                            0\n",
       "fl_open_fire                          0\n",
       "property_type                         0\n",
       "nbr_bedrooms                          0\n",
       "surface_land_sqm                      0\n",
       "zip_code                              0\n",
       "locality                              0\n",
       "province                              0\n",
       "region                                0\n",
       "subproperty_type                      0\n",
       "fl_furnished                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "df = pd.read_csv(\"../data/cleaned_properties.csv\")\n",
    "\n",
    "# Display the head\n",
    "display(df.head())\n",
    "df.shape\n",
    "df.columns\n",
    "\n",
    "# Filter the DataFrame for values APARTMENT and APARTMENT_BLOCK\n",
    "df_house1 = df[df[\"property_type\"] == \"HOUSE\"]\n",
    "df_house2 = df_house1[df_house1['subproperty_type'] != 'APARTMENT_BLOCK']\n",
    "\n",
    "df_house = df[(df[\"property_type\"] == \"HOUSE\") & (df['subproperty_type'] != 'APARTMENT_BLOCK')]\n",
    "\n",
    "df_house.head()\n",
    "print(df_house.info())\n",
    "print(df_house.shape)\n",
    "\n",
    "df_house[\"subproperty_type\"].unique()\n",
    "print(df_house[\"locality\"].unique())\n",
    "df_house.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables X and y: define the target and the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (37211, 20)\n",
      "y-shape:  (37211,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29768 entries, 8081 to 31954\n",
      "Data columns (total 20 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   region                          29768 non-null  object \n",
      " 1   province                        29768 non-null  object \n",
      " 2   total_area_sqm                  25900 non-null  float64\n",
      " 3   surface_land_sqm                29768 non-null  float64\n",
      " 4   nbr_frontages                   23670 non-null  float64\n",
      " 5   nbr_bedrooms                    29768 non-null  float64\n",
      " 6   equipped_kitchen                16580 non-null  object \n",
      " 7   fl_furnished                    29768 non-null  int64  \n",
      " 8   fl_open_fire                    29768 non-null  int64  \n",
      " 9   fl_terrace                      29768 non-null  int64  \n",
      " 10  terrace_sqm                     22712 non-null  float64\n",
      " 11  fl_garden                       29768 non-null  int64  \n",
      " 12  garden_sqm                      27915 non-null  float64\n",
      " 13  fl_swimming_pool                29768 non-null  int64  \n",
      " 14  fl_floodzone                    29768 non-null  int64  \n",
      " 15  state_building                  20592 non-null  object \n",
      " 16  primary_energy_consumption_sqm  21674 non-null  float64\n",
      " 17  epc                             22766 non-null  object \n",
      " 18  heating_type                    19124 non-null  object \n",
      " 19  fl_double_glazing               29768 non-null  int64  \n",
      "dtypes: float64(7), int64(7), object(6)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Name X and y (specific columns=subset(houses))\n",
    "X = df_house.drop(columns=['price', 'subproperty_type', 'property_type', 'zip_code', 'locality', 'construction_year', 'cadastral_income'])\n",
    "y = df_house['price']\n",
    "\n",
    "# Print shape\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"y-shape: \", y.shape)\n",
    "\n",
    "# Split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imputing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values:\n",
    "- numerical: mean\n",
    "- categorical: most frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Imputing missing values\n",
    "\n",
    "Impute missing values in both X_train and x_test\n",
    "\n",
    "So, the correct order of preprocessing steps is:\n",
    "- Impute missing values\n",
    "- Encode categorical columns\n",
    "- Rescale numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equipped_kitchen                  13188\n",
      "heating_type                      10644\n",
      "state_building                     9176\n",
      "primary_energy_consumption_sqm     8094\n",
      "terrace_sqm                        7056\n",
      "epc                                7002\n",
      "nbr_frontages                      6098\n",
      "total_area_sqm                     3868\n",
      "garden_sqm                         1853\n",
      "fl_floodzone                          0\n",
      "fl_swimming_pool                      0\n",
      "region                                0\n",
      "fl_garden                             0\n",
      "province                              0\n",
      "fl_terrace                            0\n",
      "fl_open_fire                          0\n",
      "fl_furnished                          0\n",
      "nbr_bedrooms                          0\n",
      "surface_land_sqm                      0\n",
      "fl_double_glazing                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "def impute_data(X_train):\n",
    "    \"\"\"\n",
    "    Imputes missing values in both numerical and categorical columns of the input DataFrame using SimpleImputer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input DataFrame containing columns with missing values.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Select columns with numerical and categorical data\n",
    "    numeric_cols = X_train.select_dtypes(exclude='object').columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Impute missing values for numerical columns\n",
    "    numeric_imputer = SimpleImputer(strategy='mean')  \n",
    "    X_train[numeric_cols] = numeric_imputer.fit_transform(X_train[numeric_cols])\n",
    "\n",
    "    # Impute missing values for categorical columns\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')  \n",
    "    X_train[categorical_cols] = categorical_imputer.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "    return X_train\n",
    "\n",
    "# Example usage:\n",
    "#X_train_imputed = impute_data(X_train)\n",
    "print(X_train.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "def impute_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Imputes missing values in both numerical and categorical columns of the input DataFrames using SimpleImputer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Training DataFrame containing columns with missing values.\n",
    "    X_test : pandas DataFrame\n",
    "        Testing DataFrame containing columns with missing values.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        Training and testing DataFrames with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Select columns with numerical and categorical data in training set\n",
    "    numeric_cols_train = X_train.select_dtypes(exclude='object').columns.tolist()\n",
    "    categorical_cols_train = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Select columns with numerical and categorical data in testing set\n",
    "    numeric_cols_test = X_test.select_dtypes(exclude='object').columns.tolist()\n",
    "    categorical_cols_test = X_test.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Impute missing values for numerical columns in training set\n",
    "    numeric_imputer_train = SimpleImputer(strategy='mean')  \n",
    "    X_train[numeric_cols_train] = numeric_imputer_train.fit_transform(X_train[numeric_cols_train])\n",
    "\n",
    "    # Impute missing values for categorical columns in training set\n",
    "    categorical_imputer_train = SimpleImputer(strategy='most_frequent')  \n",
    "    X_train[categorical_cols_train] = categorical_imputer_train.fit_transform(X_train[categorical_cols_train])\n",
    "\n",
    "    # Impute missing values for numerical columns in testing set\n",
    "    numeric_imputer_test = SimpleImputer(strategy='mean')  \n",
    "    X_test[numeric_cols_test] = numeric_imputer_test.fit_transform(X_test[numeric_cols_test])\n",
    "\n",
    "    # Impute missing values for categorical columns in testing set\n",
    "    categorical_imputer_test = SimpleImputer(strategy='most_frequent')  \n",
    "    X_test[categorical_cols_test] = categorical_imputer_test.fit_transform(X_test[categorical_cols_test])\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "# Apply imputing to training and test data\n",
    "X_train_encoded, X_test_encoded = impute_data(X_train.copy(), X_test.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Encode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_data(X_train):\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in the input DataFrame using OneHotEncoder.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input DataFrame containing categorical columns to be encoded.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        DataFrame with categorical columns encoded using one-hot encoding.\n",
    "    \"\"\"\n",
    "    # Select the columns with categorical values\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Initialize the encoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_array = encoder.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "    # Convert the encoded array into a DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([X_train, encoded_df], axis=1)\n",
    "\n",
    "    # Drop the original categorical columns if needed\n",
    "    result_df.drop(columns=categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "    print(result_df.isna().sum().sort_values(ascending=False)) \n",
    "\n",
    "# Example usage:\n",
    "# X_train_encoded = encode_data(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in the input DataFrames using OneHotEncoder.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input training DataFrame.\n",
    "    X_test : pandas DataFrame\n",
    "        Input test DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple of pandas DataFrames\n",
    "        Encoded training and test DataFrames.\n",
    "    \"\"\"\n",
    "    # Select the columns with categorical values\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Initialize the encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Fit and transform on training data\n",
    "    X_train_ohe = encoder.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_ohe = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "    # Convert the encoded data into DataFrames\n",
    "    X_train_ohe_df = pd.DataFrame(X_train_ohe.toarray(), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "    X_test_ohe_df = pd.DataFrame(X_test_ohe.toarray(), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "    # Drop original categorical columns from both training and test data\n",
    "    X_train.drop(columns=categorical_cols, inplace=True)\n",
    "    X_test.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "    # Concatenate encoded data with remaining data\n",
    "    X_train_ohe = pd.concat([X_train.reset_index(drop=True), X_train_ohe_df.reset_index(drop=True)], axis=1)\n",
    "    X_test_ohe = pd.concat([X_test.reset_index(drop=True), X_test_ohe_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return X_train_ohe, X_test_ohe\n",
    "\n",
    "# Apply one-hot encoding to training and test data\n",
    "X_train_ohe, X_test_ohe = one_hot_encode(X_train.copy(), X_test.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in the input DataFrames using OneHotEncoder.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Training DataFrame containing categorical columns to be encoded.\n",
    "    X_test : pandas DataFrame\n",
    "        Testing DataFrame containing categorical columns to be encoded.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame, pandas DataFrame\n",
    "        DataFrames with categorical columns encoded using one-hot encoding for both training and testing datasets.\n",
    "    \"\"\"\n",
    "    # Select the columns with categorical values in training set\n",
    "    categorical_cols_train = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Select the columns with categorical values in testing set\n",
    "    categorical_cols_test = X_test.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Initialize the encoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "    # Fit and transform encoder on training data\n",
    "    encoded_array_train = encoder.fit_transform(X_train[categorical_cols_train])\n",
    "    encoded_array_test = encoder.transform(X_test[categorical_cols_test])\n",
    "\n",
    "    # Convert the encoded arrays into DataFrames\n",
    "    encoded_df_train = pd.DataFrame(encoded_array_train, columns=encoder.get_feature_names_out(categorical_cols_train))\n",
    "    encoded_df_test = pd.DataFrame(encoded_array_test, columns=encoder.get_feature_names_out(categorical_cols_test))\n",
    "\n",
    "    # Concatenate the encoded DataFrames with the original DataFrames for both training and testing sets\n",
    "    result_df_train = pd.concat([X_train, encoded_df_train], axis=1)\n",
    "    result_df_test = pd.concat([X_test, encoded_df_test], axis=1)\n",
    "\n",
    "    # Drop the original categorical columns if needed\n",
    "    result_df_train.drop(columns=categorical_cols_train, axis=1, inplace=True)\n",
    "    result_df_test.drop(columns=categorical_cols_test, axis=1, inplace=True)\n",
    "\n",
    "    return result_df_train, result_df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rescaling numeric features with standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_numeric_features(X_train_ohe, X_test_ohe):\n",
    "    \"\"\"\n",
    "    Scale the numeric features in the training and test datasets using StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train_ohe (DataFrame): DataFrame containing the training data with both numeric and non-numeric features.\n",
    "    - X_test_ohe (DataFrame): DataFrame containing the test data with both numeric and non-numeric features.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_stdv (DataFrame): DataFrame containing the scaled numeric features concatenated with the non-numeric features for training data.\n",
    "    - X_test_stdv (DataFrame): DataFrame containing the scaled numeric features concatenated with the non-numeric features for test data.\n",
    "    \"\"\"\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Select numeric features for training data\n",
    "    numeric_features_train = X_train_ohe.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "    # Fit and transform the numeric features in the training set\n",
    "    scaled_features_train = scaler.fit_transform(numeric_features_train)\n",
    "\n",
    "    # Convert the scaled training features array back to a DataFrame\n",
    "    scaled_df_train = pd.DataFrame(scaled_features_train, columns=numeric_features_train.columns)\n",
    "\n",
    "    # Select numeric features for test data\n",
    "    numeric_features_test = X_test_ohe.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "    # Transform the numeric features in the test set\n",
    "    scaled_features_test = scaler.transform(numeric_features_test)\n",
    "\n",
    "    # Convert the scaled test features array back to a DataFrame\n",
    "    scaled_df_test = pd.DataFrame(scaled_features_test, columns=numeric_features_test.columns)\n",
    "\n",
    "    # Concatenate scaled numeric features with other columns in the original DataFrames\n",
    "    X_train_stdv = pd.concat([X_train_ohe.drop(numeric_features_train.columns, axis=1), scaled_df_train], axis=1)\n",
    "    X_test_stdv = pd.concat([X_test_ohe.drop(numeric_features_test.columns, axis=1), scaled_df_test], axis=1)\n",
    "\n",
    "    return X_train_stdv, X_test_stdv\n",
    "\n",
    "# Example usage:\n",
    "X_train_stdv, X_test_stdv = scale_numeric_features(X_train_ohe, X_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pipeline: Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Preprocesses training and test data including imputation, encoding, and scaling.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pandas DataFrame\n",
    "        Input training DataFrame.\n",
    "    X_test : pandas DataFrame\n",
    "        Input test DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple of pandas DataFrames\n",
    "        Preprocessed training and test DataFrames.\n",
    "    \"\"\"\n",
    "    # Separate numerical and categorical columns\n",
    "    numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Define preprocessing steps for numerical and categorical data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "    # Fit and transform the preprocessing steps on training data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Convert the processed data into DataFrames\n",
    "    X_train_processed = pd.DataFrame(X_train_processed, columns=numeric_cols.tolist() +\n",
    "                                     preprocessor.named_transformers_['cat']\n",
    "                                     .named_steps['onehot'].get_feature_names_out(categorical_cols).tolist())\n",
    "    X_test_processed = pd.DataFrame(X_test_processed, columns=numeric_cols.tolist() +\n",
    "                                    preprocessor.named_transformers_['cat']\n",
    "                                    .named_steps['onehot'].get_feature_names_out(categorical_cols).tolist())\n",
    "\n",
    "    return X_train_processed, X_test_processed\n",
    "\n",
    "# Preprocess training and test data\n",
    "X_train_processed, X_test_processed = preprocess_data(X_train, X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
